[data]
seed = 1
dataset = corafull
valid_ratio = 0.2
test_ratio = 0.2
# num_parts = 15000
num_parts = 1

[training]
train_ratio = 0.6
# batch_size = 1024
batch_size = 1 
[model]
model = GCN_GW
gnn_hidden_dim = 128
num_layers = 2
epoch = 500
lr = 0.01
init_memory = False
gw_ratio = 0.3
emb_dim=128
shared_memory_attention = True
shared_memory_percentage = 0.4
mem_slots = 64
encoder_attention_heads = 8
encoder_embed_dim =  128
encoder_ffn_embed_dim = 256
attention_dropout = 0.3
topk_ratio = 1.0
encoder_normalize_before = False
null_attention = False
regressive = False
use_nfm = False
self_attention = True
dropout = 0.5

use_topk = False
topk = 3
num_steps = 5




[log]
log_step = 20
log_dir=experiments_rebuttal
plot = False
debug = False
device = cuda:2